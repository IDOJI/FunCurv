# ğŸŸ¥ Load Functions & Packages ##########################################################################
# rm(list = ls())
Sys.setlocale("LC_ALL", "en_US.UTF-8")

## ğŸŸ¨Install and loading Packages ================================
install_packages = function(packages, load=TRUE) {
  # load : load the packages after installation?
  for(pkg in packages) {
    if (!require(pkg, character.only = TRUE)) {
      install.packages(pkg)
    }
    
    if(load){
      library(pkg, character.only = TRUE, quietly = T)
    }
  }
}

List.list = list()
List.list[[1]] = visual = c("ggpubr", "ggplot2", "ggstatsplot", "ggsignif", "rlang", "RColorBrewer", "reshape2")
List.list[[2]] = stat = c("fda", "MASS", "caret")
List.list[[3]] = data_handling = c("tidyverse", "dplyr", "clipr", "tidyr", "readr", "caret", "readxl")
List.list[[4]] = qmd = c("janitor", "knitr")
List.list[[5]] = texts = c("stringr", "stringi")
List.list[[6]] = misc = c("devtools")
List.list[[7]] = db = c("RMySQL", "DBI", "odbc", "RSQL", "RSQLite")
List.list[[8]] = sampling = c("rsample")
List.list[[9]] = excel = c("openxlsx")
List.list[[10]] = others = c("beepr")

packages_to_install_and_load = unlist(List.list)
install_packages(packages_to_install_and_load)

## ğŸŸ§dplyr =======================================================
filter = dplyr::filter
select = dplyr::select




# ğŸŸ¥ Define smoothing functions =========================================================================================================
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ë¡œë“œ
library(dplyr)
library(caret)
library(fda)
library(purrr)
library(crayon)

# 1) ë°ì´í„° ìƒ˜í”Œë§ í•¨ìˆ˜
bootstrap_sample <- function(data, sample_size = NULL) {
  if (is.null(sample_size)) {
    sample_size <- nrow(data)
  }
  
  data %>%
    group_by(DIAGNOSIS_FINAL) %>%
    sample_frac(size = sample_size / nrow(data), replace = TRUE) %>%
    ungroup()
}

# 2) ë°ì´í„° ë¶„í•  í•¨ìˆ˜ (Train/Test)
split_data <- function(data, train_ratio = 0.7) {
  set.seed(123)  # ì¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œ ì„¤ì •
  train_index <- createDataPartition(data$DIAGNOSIS_FINAL, p = train_ratio, list = FALSE)
  train_data <- data[train_index, ]
  test_data <- data[-train_index, ]
  list(train = train_data, test = test_data)
}

# 3) K-Fold ë¶„í•  í•¨ìˆ˜
create_folds <- function(train_data, k = 5) {
  set.seed(123)
  folds <- createFolds(train_data$DIAGNOSIS_FINAL, k = k, returnTrain = TRUE)
  fold_list <- lapply(1:k, function(i) {
    validation_index <- setdiff(1:nrow(train_data), folds[[i]])
    list(
      train = train_data[folds[[i]], ],
      validation = train_data[validation_index, ]
    )
  })
  names(fold_list) <- paste0("Fold_", 1:k)
  fold_list
}

# 4) Smoothing ë° FPCA í•¨ìˆ˜
perform_smoothing_fpca <- function(train_data, validation_data, domain, n_order = 4, n_breaks = NULL, lambda = 1e-4, nharm = 5) {
  # Smoothing
  basis <- create.bspline.basis(rangeval = c(min(domain), max(domain)), norder = n_order, nbasis = ifelse(is.null(n_breaks), length(domain), n_breaks))
  fdPar_obj <- fdPar(basis, Lfdobj = int2Lfd(2), lambda = lambda)
  
  # Train ë°ì´í„° smoothing
  train_fd <- smooth.basis(argvals = domain, y = t(train_data), fdParobj = fdPar_obj)$fd
  
  # FPCA
  fpca_result <- pca.fd(train_fd, nharm = nharm, centerfns = TRUE)
  
  # Validation ë°ì´í„° smoothing
  validation_fd <- smooth.basis(argvals = domain, y = t(validation_data), fdParobj = fdPar_obj)$fd
  
  # Validation ë°ì´í„°ì—ì„œ FPC score ê³„ì‚°
  validation_scores <- inprod(validation_fd, fpca_result$harmonics)
  
  list(
    fpca_result = fpca_result,
    train_scores = fpca_result$scores,
    validation_scores = validation_scores
  )
}

# 5) Functional Logistic Regression ë° ì„±ëŠ¥ í‰ê°€ í•¨ìˆ˜
evaluate_model <- function(train_scores, train_labels, validation_scores, validation_labels) {
  # ëª¨ë¸ ì í•©
  model <- glm(train_labels ~ ., data = as.data.frame(train_scores), family = binomial)
  
  # ì˜ˆì¸¡
  predictions <- predict(model, newdata = as.data.frame(validation_scores), type = "response")
  predicted_classes <- ifelse(predictions > 0.5, 1, 0)
  
  # ì„±ëŠ¥ í‰ê°€
  confusion <- confusionMatrix(as.factor(predicted_classes), as.factor(validation_labels))
  performance <- list(
    accuracy = confusion$overall['Accuracy'],
    kappa = confusion$overall['Kappa']
  )
  
  performance
}

# 6) í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° ìµœì¢… ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
tune_and_evaluate <- function(fold_results, test_scores, test_labels) {
  # ê° foldì˜ ì„±ëŠ¥ ìˆ˜ì§‘
  performances <- map(fold_results, "performance")
  
  # ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„ íƒ (ì˜ˆ: accuracy ê¸°ì¤€)
  best_fold <- which.max(map_dbl(performances, "accuracy"))
  
  # ìµœì  ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
  best_model <- fold_results[[best_fold]]$model
  predictions <- predict(best_model, newdata = as.data.frame(test_scores), type = "response")
  predicted_classes <- ifelse(predictions > 0.5, 1, 0)
  
  # ìµœì¢… ì„±ëŠ¥ í‰ê°€
  confusion <- confusionMatrix(as.factor(predicted_classes), as.factor(test_labels))
  final_performance <- list(
    accuracy = confusion$overall['Accuracy'],
    kappa = confusion$overall['Kappa']
  )
  
  final_performance
}



# ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
run_analysis <- function(subject_data, domain, sample_size = NULL, train_ratio = 0.7, k_folds = 5, n_order = 4, n_breaks = NULL, lambda = 1e-4, nharm = 5) {
  # 1) ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œë§
  sampled_data <- bootstrap_sample(subject_data, sample_size)
  
  # 2) Train/Test ë¶„í• 
  split <- split_data(sampled_data, train_ratio)
  train_data <- split$train
  test_data <- split$test
  
  # ë ˆì´ë¸” ì¶”ì¶œ
  test_labels <- test_data$DIAGNOSIS_FINAL
  
  # 3) K-Fold ìƒì„±
  folds <- create_folds(train_data, k = k_folds)
  
  # 4) ê° Foldì— ëŒ€í•´ Smoothing ë° FPCA ìˆ˜í–‰
  fold_results <- lapply(folds, function(fold) {
    train_fold <- fold$train
    validation_fold <- fold$validation
    
    # ë°ì´í„° ì¤€ë¹„ (ì˜ˆì‹œë¡œ í•„ìš”í•œ ë³€ìˆ˜ë§Œ ì¶”ì¶œ)
    train_matrix <- as.matrix(train_fold[ , -which(names(train_fold) %in% c("RID", "DIAGNOSIS_FINAL"))])
    validation_matrix <- as.matrix(validation_fold[ , -which(names(validation_fold) %in% c("RID", "DIAGNOSIS_FINAL"))])
    
    # Smoothing ë° FPCA ìˆ˜í–‰
    fpca <- perform_smoothing_fpca(train_matrix, validation_matrix, domain, n_order, n_breaks, lambda, nharm)
    
    # 5) ëª¨ë¸ ì í•© ë° ì„±ëŠ¥ í‰ê°€
    performance <- evaluate_model(fpca$train_scores, train_fold$DIAGNOSIS_FINAL, fpca$validation_scores, validation_fold$DIAGNOSIS_FINAL)
    
    list(
      model = glm(train_fold$DIAGNOSIS_FINAL ~ ., data = as.data.frame(fpca$train_scores), family = binomial),
      performance = performance
    )
  })
  
  # 7) ì „ì²´ Train ë°ì´í„°ë¡œ FPCA ìˆ˜í–‰
  total_train_matrix <- as.matrix(train_data[ , -which(names(train_data) %in% c("RID", "DIAGNOSIS_FINAL"))])
  test_matrix <- as.matrix(test_data[ , -which(names(test_data) %in% c("RID", "DIAGNOSIS_FINAL"))])
  
  total_fpca <- perform_smoothing_fpca(total_train_matrix, test_matrix, domain, n_order, n_breaks, lambda, nharm)
  
  # 6) ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
  final_performance <- tune_and_evaluate(fold_results, total_fpca$validation_scores, test_labels)
  
  final_performance
}

# í•¨ìˆ˜ ì‹¤í–‰ ì˜ˆì‹œ
# domainì€ ê´€ì¸¡ëœ ë°ì´í„°ì˜ ë„ë©”ì¸ (ì˜ˆ: ì‹œê°„ ë˜ëŠ” ê³µê°„ ì¢Œí‘œ)
# subject_dataëŠ” RID, DIAGNOSIS_FINAL ë° ê´€ì¸¡ ë°ì´í„°ê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„

# ì˜ˆì‹œ ë°ì´í„° ë¡œë“œ (ì‚¬ìš©ìì˜ ì‹¤ì œ ë°ì´í„°ë¡œ ëŒ€ì²´í•´ì•¼ í•¨)
# subject_data <- read.csv("your_subject_data.csv")
# domain <- seq(0, 1, length.out = ncol(subject_data) - 2)

# ê²°ê³¼ ì‹¤í–‰
# result <- run_analysis(subject_data, domain)
# print(result)






