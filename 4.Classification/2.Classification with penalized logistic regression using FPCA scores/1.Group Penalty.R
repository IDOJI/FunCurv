# ğŸŸ© Load data =========================================================================================================
path_data_list = "/Users/Ido/Library/CloudStorage/Dropbox/âœ´ï¸DataAnalysis/FunCurv/3.Classification/1.FPCA"
path_all_data_list = list.files(path_data_list, full.names = T)
path_save = "/Volumes/ADNI_SB_SSD_NTFS_4TB_Sandisk/FunCurv/3.Classification/2.Classification with penalized logistic regression using FPCA scores/1.Group Penalty"







# ğŸŸ¨ Group Penalty =========================================================================================================
# alphas = seq(0.1, 1, by = 0.1)  # alpha: 0.1ì—ì„œ 1ê¹Œì§€ 0.1 ê°„ê²©
# lambdas = 10^seq(3, -3, length.out = 100)  # lambda: log scaleì—ì„œ 100ê°œì˜ ê°’
# penalties = c("grLasso", "grMCP", "grSCAD", "gel", "cMCP")
# 
# for(path_ith_data in path_all_data_list){
#   # path_ith_data = path_all_data_list[2]
#   ith_data = basename(path_ith_data)
#   path_save_new = file.path(path_save, ith_data)
#   dir.create(path_save_new, showWarnings = F)
#   exported_file = file.path(path_save_new, "classification results.rds")
#   if(file.exists(exported_file)){
#     next
#   }
#   
#   # Load the data
#   path_ith_data_fpca = list.files(path_ith_data, full.names = T, pattern = "fpca_scores")
#   fpca_scores = readRDS(path_ith_data_fpca)
#   fpca_scores_train = fpca_scores$train
#   fpca_scores_test = fpca_scores$test
#   fpca_scores_rep = fpca_scores$rep
#   
#   # Model fitting
#   opt_models_list = lapply(penalties, function(penalty){
#     find_opt_model_by_cv_grpreg(fpca_scores_train,
#                                 fpca_scores_test,
#                                 fpca_scores_rep,
#                                 alphas,
#                                 lambdas,
#                                 penalty = penalty)
#     
#   }) %>% setNames(penalties)
#   
#   
#   # save the results
#   saveRDS(opt_models_list, exported_file)
#   
# }





# ğŸŸ¨ PROAUC ê²°ê³¼ ì¶”ì¶œ =========================================================================================================
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ë¡œë“œ
library(readr)
library(dplyr)
library(purrr)
library(writexl)

# ê° ë°ì´í„° ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°
path_all_measures <- list.files(path_save, full.names = TRUE)

## ğŸŸ§ ê²°ê³¼ ì¶”ì¶œ ================================================================
# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
result_list <- list()

 
# ê° ë°ì´í„° ê²½ë¡œì— ëŒ€í•´ ë°˜ë³µ ìˆ˜í–‰
for (path_ith_measure in path_all_measures) {
  path_ith_results <- list.files(path_ith_measure, full.names = TRUE)
  
  ith_PRAUC <- lapply(seq(path_ith_results), function(j) {
    ij_result <- readRDS(path_ith_results[j])
    
    # ê° ë°©ë²•ë¡ ì˜ PRAUC ê°’ì„ ì¶”ì¶œ
    ij_PRAUC <- lapply(ij_result$optimal_models, function(x) {
      return(x$best_pr_auc)
    }) %>% setNames(names(ij_result$optimal_models))
    
    return(ij_PRAUC)
  }) %>% setNames(tools::file_path_sans_ext(basename(path_ith_results)))
  
  # ë°ì´í„° í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
  result_list[[basename(path_ith_measure)]] <- ith_PRAUC
}




## ğŸŸ§ ìµœëŒ“ê°’ë§Œ í™•ì¸  ================================================================
result_list %>% unlist %>% max
head(result_list)



## ğŸŸ§ ê²°ê³¼ í•©ì¹˜ê¸° ================================================================
# ê²°ê³¼ë¥¼ í•©ì³ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ë°ì´í„°ì…‹ ì´ë¦„ì„ ì²« ë²ˆì§¸ ì—´ë¡œ ì¶”ê°€)
combined_df <- map_dfr(names(result_list), function(dataset_name) {
  data <- result_list[[dataset_name]]
  map_dfr(names(data), function(method) {
    tibble(
      Dataset = dataset_name,
      Method = method,
      Hyperparameters = names(data[[method]]),
      PRAUC = unlist(data[[method]])
    )
  })
})


# View(combined_df)



## ğŸŸ§ ê²°ê³¼ ë‚´ë³´ë‚´ê¸° ===================================================================
# ì—‘ì…€ íŒŒì¼ ìƒì„± ë° ì‹œíŠ¸ ì¶”ê°€
wb <- createWorkbook()
addWorksheet(wb, "CombinedResults")

# ë°ì´í„°í”„ë ˆì„ì„ ì—‘ì…€ ì‹œíŠ¸ì— ì‘ì„±
writeData(wb, "CombinedResults", combined_df)

# ìµœëŒ“ê°’ì¸ PRAUC í–‰ ì°¾ê¸°
max_prauc_row <- which.max(combined_df$PRAUC)

# max PRAUC í–‰ì— ìƒ‰ìƒ ì ìš© (ë…¸ë€ìƒ‰)
highlight_style <- createStyle(bgFill = "yellow")
addStyle(
  wb, "CombinedResults",
  style = highlight_style,
  rows = max_prauc_row + 1, # í—¤ë”ê°€ ìˆìœ¼ë¯€ë¡œ +1
  cols = 1:ncol(combined_df),
  gridExpand = TRUE
)

# ì—‘ì…€ íŒŒì¼ ì €ì¥
path_export <- "/Volumes/ADNI_SB_SSD_NTFS_4TB_Sandisk/FunCurv/3.Classification/2.Classification with penalized logistic regression using FPCA scores"
saveWorkbook(wb, file.path(path_export, "PRAUC_results.xlsx"), overwrite = TRUE)



## ğŸŸ© ìµœëŒ“ê°’ ëª¨í˜•ì„ ë‹¤ì‹œ ì í•©í•´ì„œ ì—¬ëŸ¬ ê°’ë“¤ ì¶”ì¶œ===========================================
set_label <- function(vector) {
  # "AD"ê°€ ì¡´ì¬í•˜ë©´, "AD"ë¥¼ 1ë¡œ, ë‚˜ë¨¸ì§€ë¥¼ 0ìœ¼ë¡œ ì„¤ì •
  if ("Dementia" %in% vector) {
    return(ifelse(vector == "Dementia", 1, 0))
  }
  
  # "AD"ê°€ ì—†ê³  "MCI"ê°€ ì¡´ì¬í•˜ë©´, "MCI"ë¥¼ 1ë¡œ, ë‚˜ë¨¸ì§€ë¥¼ 0ìœ¼ë¡œ ì„¤ì •
  if ("MCI" %in% vector) {
    return(ifelse(vector == "MCI", 1, 0))
  }
  
  # "AD"ì™€ "MCI"ê°€ ëª¨ë‘ ì—†ìœ¼ë©´, ëª¨ë“  ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •
  return(rep(0, length(vector)))
}

a = 0.1
l = 0.174752840000768
pen = "grLasso"
# fpca = readRDS("/Volumes/ADNI_SB_SSD_NTFS_4TB_Sandisk/FunCurv/3.Classification/1.FPCA/MCI_CN___FunImgARglobalCWSF_Fisher Z FC/fpca_scores.rds")

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ë¡œë“œ
library(dplyr)
library(grpreg)
library(pROC)  # AUC ê³„ì‚°ì„ ìœ„í•´ pROC íŒ¨í‚¤ì§€ ì‚¬ìš©
library(caret) # ë¯¼ê°ë„, íŠ¹ì´ë„, ì •í™•ë„ ê³„ì‚°ì„ ìœ„í•´ caret íŒ¨í‚¤ì§€ ì‚¬ìš©

# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
results_list <- list()

# ê° foldì— ëŒ€í•´ ë°˜ë³µ ìˆ˜í–‰
for (k in seq_along(fpca$train)) {
  # kë²ˆì§¸ foldì˜ train/test ë°ì´í„° ì„¤ì •
  kth_train <- fpca$train[[k]]
  kth_test <- fpca$test[[k]]
  
  # ëª¨ë¸ í•™ìŠµ
  kth_results <- grpreg(
    X = kth_train %>% dplyr::select(-RID, -DX) %>% as.matrix, 
    y = kth_train %>% pull(DX) %>% set_label,
    group = fpca$rep[[k]], 
    penalty = pen,
    lambda = l,
    alpha = a
  )
  
  predictions <- predict(kth_results, kth_test %>% dplyr::select(-RID, -DX) %>% as.matrix, type = "response")
  actuals <- kth_test %>% pull(DX) %>% set_label
  
  # ROC ë° AUC ê³„ì‚°
  roc_obj <- roc(actuals, predictions)
  auc_value <- auc(roc_obj)
  
  # ì´ì§„ ì˜ˆì¸¡ (ì„ê³„ê°’ 0.5 ì ìš©)
  predicted_class <- ifelse(predictions > 0.5, 1, 0)
  
  # í˜¼ë™ í–‰ë ¬ ìƒì„±
  confusion_matrix <- confusionMatrix(
    factor(predicted_class, levels = c(0, 1)),
    factor(actuals, levels = c(0, 1))
  )
  
  # ë¯¼ê°ë„, íŠ¹ì´ë„, ì •í™•ë„ ì¶”ì¶œ
  sensitivity <- confusion_matrix$byClass["Sensitivity"]
  specificity <- confusion_matrix$byClass["Specificity"]
  accuracy <- confusion_matrix$overall["Accuracy"]
  
  # fold ê²°ê³¼ ì €ì¥
  results_list[[k]] <- list(
    AUC = auc_value,
    Sensitivity = sensitivity,
    Specificity = specificity,
    Accuracy = accuracy
  )
}
# foldë³„ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜ í›„ í‰ê·  ê³„ì‚°
results_df <- do.call(rbind, results_list) %>% as.data.frame()

# ë°ì´í„°í”„ë ˆì„ì˜ ëª¨ë“  ì—´ì„ numeric íƒ€ì…ìœ¼ë¡œ ë³€í™˜
results_df <- results_df %>% mutate(across(everything(), as.numeric))

# ê° ë©”íŠ¸ë¦­ì˜ í‰ê· ê°’ ê³„ì‚°
average_results <- colMeans(results_df, na.rm = TRUE)

# ìµœì¢… ê²°ê³¼ ì¶œë ¥
average_results









